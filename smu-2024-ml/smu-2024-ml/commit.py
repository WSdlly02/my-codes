'''
è¿™æ˜¯æœ€å¥½ä¸€æ¬¡æäº¤çš„èƒŒåçš„ä»£ç 
(å¯èƒ½æŠŠ,å› ä¸ºæˆ‘æœ‰å¥½å¤šä¸ªç‰ˆæœ¬,ä¸å¤ªç¡®å®š,ä¸è¿‡ä¹Ÿæ— æ‰€è°“äº†)
ç”±äºåªè¦è€ƒè™‘è¾“å‡º.csvå°±è¡Œ,æ‰€ä»¥é™ç»´,ç”Ÿæˆä¸‰ç»´ç½‘æ ¼ä¹‹ç±»çš„ä»£ç å°±ç»Ÿç»Ÿä¸è¦äº†
'''
import os
import random
import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import log_loss
from sklearn.ensemble import RandomForestClassifier
from tqdm.auto import tqdm

np.random.seed(42)
random.seed(42)
os.environ['PYTHONHASHSEED'] = str(42)

df_train = pd.read_csv("input/train.csv")
df_test = pd.read_csv("input/test.csv")

# å‚æ•°
class configs:
    target_col = "target"
    unused_col = [target_col, "fold", "id"]
    FOLDS = 5

configs.feat_cols = [col for col in df_train.columns if col not in configs.unused_col]
y_train = df_train[configs.target_col]
X_train = df_train[configs.feat_cols]
X_test = df_test[configs.feat_cols]

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

'''
è°ƒæ•´æƒé‡
åŸºæœ¬æ€è·¯å°±æ˜¯è°ƒæ•´è¿™24ä¸ªç»´åº¦æ•°æ®çš„æƒé‡,ä¹‹åå†è¶…å‚æ•°ä¼˜åŒ–ä¸€ä¸‹,å¼‚å¸¸å€¼è¿™ä¸ªæ²¡å»ç®¡å®ƒ
è‡³äºå…·ä½“æƒé‡æ˜¯æ€ä¹ˆç®—å‡ºæ¥çš„?ä¸€éƒ¨åˆ†çœ‹å¾—æ‡‚çš„å…ˆå¡«ä¸€ä¸‹å¤§è‡´å…³ç³»,çœ‹ä¸æ‡‚çš„ä¸ç®¡äº†
ä¹‹åå†æ ¹æ®lossæ•°æ®åæ¨
æœ‰ç‚¹æ ¹æ®ç­”æ¡ˆå‡ºé¢˜ç›®çš„æ„æ€,å“ˆå“ˆğŸ˜„
'''
feature_weights = {
    'risk_assessment_score': 3.0,  # é«˜é£é™©è¯„ä¼°å¾—åˆ†ä¸è¿çº¦é£é™©ç›´æ¥ç›¸å…³
    'first_trade_elapsed_time': 1.5,  # å®¢æˆ·äº¤æ˜“å†å²è¶Šé•¿,è¿çº¦é£é™©è¶Šä½
    'recent_trade_gap': 1.2,  # è¿‘æœŸäº¤æ˜“æ´»è·ƒåº¦è¶Šé«˜,è¿çº¦é£é™©è¶Šä½
    'avg_time_to_resolve': 1.0,  # å¹³å‡é—®é¢˜è§£å†³æ—¶é—´,ä¸çŸ¥é“
    'total_successful_trades': 2.5,  # æˆåŠŸäº¤æ˜“æ€»æ•°è¶Šå¤š,è¿çº¦é£é™©è¶Šä½
    'delinquent_trades_60_days': 3.0,  # 60å¤©ä»¥ä¸Šæ‹–æ¬ äº¤æ˜“è¶Šå¤š,è¿çº¦é£é™©è¶Šé«˜
    'delinquent_trades_90_days': 3.0,  # 90å¤©ä»¥ä¸Šæ‹–æ¬ äº¤æ˜“è¶Šå¤š,è¿çº¦é£é™©è¶Šé«˜
    'legal_trade_percentage': 1.0,  # åˆæ³•äº¤æ˜“ç™¾åˆ†æ¯”
    'last_illegal_trade_gap': 2.5,  # æœ€è¿‘ä¸€æ¬¡éæ³•äº¤æ˜“æ—¶é—´
    'illegal_trades_last_year_max': 3.0,  # è¿‡å»ä¸€å¹´å†…æœ€å¤§éæ³•äº¤æ˜“
    'total_illegal_trades_max': 3.0,  # æ‰€æœ‰éæ³•äº¤æ˜“ä¸­çš„æœ€å¤§å€¼
    'total_trade_count': 2.0,  # æ€»äº¤æ˜“æ•°è¶Šå¤š,è¿çº¦é£é™©è¶Šä½
    'recently_initiated_trades': 1.5,  # æœ€è¿‘å‘èµ·çš„äº¤æ˜“æ•°
    'installment_trade_percentage': 1.0,  # åˆ†æœŸä»˜æ¬¾äº¤æ˜“ç™¾åˆ†æ¯”
    'non_recent_inquiry_gap': 1.0,  # è¾ƒé•¿æ—¶é—´å†…çš„ä¿¡ç”¨æŸ¥è¯¢
    'recent_inquiries_count': 2.0,  # è¿‘æœŸå†…çš„æŸ¥è¯¢æ€»æ•°
    'non_recent_inquiries_count': 1.0,  # éè¿‘æœŸçš„æŸ¥è¯¢æ€»æ•°
    'revolving_debt_ratio': 2.5,  # å¾ªç¯ä¿¡ç”¨è´Ÿå€ºæ¯”ä¾‹
    'installment_debt_ratio': 2.0,  # åˆ†æœŸä»˜æ¬¾è´Ÿå€ºæ¯”ä¾‹
    'revolving_trades_with_balance': 2.0,  # æœ‰ä½™é¢çš„å¾ªç¯ä¿¡ç”¨äº¤æ˜“æ•°
    'installment_trades_with_balance': 2.0,  # æœ‰ä½™é¢çš„åˆ†æœŸä»˜æ¬¾äº¤æ˜“æ•°
    'high_risk_banks_count': 3.0,  # é«˜é£é™©è´¦æˆ·æ•°
    'trades_with_balance_percentage': 2.5  # æœ‰ä½™é¢çš„äº¤æ˜“ç™¾åˆ†æ¯”
}

# æ ¹æ®æƒé‡è°ƒæ•´è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
X_train_weighted = X_train_scaled.copy()
X_test_weighted = X_test_scaled.copy()

for feature, weight in feature_weights.items():
    X_train_weighted[:, configs.feat_cols.index(feature)] *= weight
    X_test_weighted[:, configs.feat_cols.index(feature)] *= weight

# éšæœºæ£®æ—
rf_model = RandomForestClassifier(random_state=42)
'''
è¶…å‚æ•°è°ƒä¼˜çš„å‚æ•°
è¿™æ®µæ€ä¹ˆæ¥çš„?ä¸ä¼šå†™,è®©gptå¸®æˆ‘å†™çš„ğŸ¤£
è¿™ç©æ„çœŸçš„ææ€–,å‰é¢çš„ä»£ç å­å“§å­å“§å†™åŠå¤©,è¿™å‡ è¡ŒæŒ‰ä¸ªå›è½¦ä¸€ä¸‹å­å°±æå¥½äº†
'''
param_dist = {
    'n_estimators': [100, 200, 500],
    'max_depth': [3, 6, 10, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}
# è¶…å‚æ•°è°ƒä¼˜
random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=100, scoring='neg_log_loss', cv=StratifiedKFold(n_splits=configs.FOLDS), verbose=1, random_state=42, n_jobs=-1)
random_search.fit(X_train_weighted, y_train)
best_rf_model = random_search.best_estimator_

# äº¤å‰éªŒè¯å’Œé¢„æµ‹
# å’ŒåŸå…ˆsvm-baselineçš„ä»£ç å·®ä¸å¤š
cv = StratifiedKFold(n_splits=configs.FOLDS)
y_pred_train = np.zeros(len(X_train))
y_pred_test = np.zeros(len(X_test))
scores = []

for train_index, val_index in tqdm(cv.split(X_train_weighted, y_train)):
    X_train_, y_train_ = X_train_weighted[train_index], y_train[train_index]
    X_val, y_val = X_train_weighted[val_index], y_train[val_index]
    best_rf_model.fit(X_train_, y_train_)
    y_pred_val = best_rf_model.predict_proba(X_val)[:, 1]
    y_pred_train[val_index] = y_pred_val
    y_pred_test += best_rf_model.predict_proba(X_test_weighted)[:, 1] / configs.FOLDS
    score = log_loss(y_val, y_pred_val)
    scores.append(score)
    print(f"Fold Log Loss: {score:.6f}")

print(f"Overall Log Loss: {np.mean(scores):.6f} Â± {np.std(scores):.6f}")

submission = pd.DataFrame({
    'id': df_test['id'],
    'target': y_pred_test
})
submission.to_csv('output/submission-5.csv', index=False)
